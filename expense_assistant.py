# Tr·ª£ L√Ω B√°o C√°o Chi Ph√≠ - Module Ch√≠nh
"""
Tr·ª£ l√Ω b√°o c√°o chi ph√≠ ƒë∆∞·ª£c h·ªó tr·ª£ AI v·ªõi qu·∫£n l√Ω h·ªôi tho·∫°i,
g·ªçi h√†m v√† kh·∫£ nƒÉng h∆∞·ªõng d·∫´n ch√≠nh s√°ch.
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import re
from dotenv import load_dotenv
from openai import OpenAI
from database import ExpenseDB

# Load environment variables
load_dotenv()

class ExpenseAssistant:
    """
    Tr·ª£ l√Ω b√°o c√°o chi ph√≠ ƒë∆∞·ª£c h·ªó tr·ª£ AI v·ªõi qu·∫£n l√Ω h·ªôi tho·∫°i,
    g·ªçi h√†m v√† kh·∫£ nƒÉng h∆∞·ªõng d·∫´n ch√≠nh s√°ch.
    """
    
    def __init__(self, client, model="GPT-4o-mini"):
        self.client = client
        self.model = model
        self.conversation_history = []
        self.user_context = {}  # Store user-specific context
        
        # Initialize ChromaDB connection
        self.db = ExpenseDB()
        
        # System prompt v·ªõi v√≠ d·ª• few-shot v√† ch√≠nh s√°ch c√¥ng ty
        self.system_prompt = """B·∫°n l√† Tr·ª£ L√Ω Th√¥ng Minh c·ªßa c√¥ng ty, ƒë∆∞·ª£c trang b·ªã ChromaDB knowledge base ƒë·ªÉ h·ªó tr·ª£ nh√¢n vi√™n to√†n di·ªán. 

VAI TR√í CH√çNH:
1. üí∞ Tr·ª£ l√Ω b√°o c√°o chi ph√≠ chuy√™n nghi·ªáp
2. ü§ñ Chatbot h·ªó tr·ª£ th√¥ng tin c√¥ng ty t·ªïng qu√°t  
3. üìö T∆∞ v·∫•n ch√≠nh s√°ch v√† quy ƒë·ªãnh c√¥ng ty
4. üîç T√¨m ki·∫øm v√† cung c·∫•p th√¥ng tin t·ª´ knowledge base

KH·∫¢ NƒÇNG CH√çNH:
‚Ä¢ Tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ ch√≠nh s√°ch chi ph√≠ v√† c√¥ng ty
‚Ä¢ T√≠nh to√°n v√† x√°c th·ª±c ho√†n ti·ªÅn chi ph√≠
‚Ä¢ H∆∞·ªõng d·∫´n quy tr√¨nh v√† th·ªß t·ª•c
‚Ä¢ Cung c·∫•p th√¥ng tin t·ª´ FAQs v√† knowledge base
‚Ä¢ H·ªó tr·ª£ c√°c c√¢u h·ªèi t·ªïng qu√°t v·ªÅ c√¥ng ty

NGU·ªíN TH√îNG TIN CHROMADB:
- üìã Expense Policies: Ch√≠nh s√°ch chi ph√≠ chi ti·∫øt
- ‚ùì General FAQs: C√¢u h·ªèi th∆∞·ªùng g·∫∑p
- üìö Company Knowledge: Th√¥ng tin t·ªïng qu√°t c√¥ng ty
- üìä Categories & Reports: Danh m·ª•c v√† b√°o c√°o m·∫´u

T√ìM T·∫ÆT CH√çNH S√ÅCH CHI PH√ç:
- H√≥a ƒë∆°n c·∫ßn thi·∫øt cho chi ph√≠ > 500.000 VNƒê
- ƒÇn u·ªëng: 1.000.000 VNƒê/ng√†y (trong n∆∞·ªõc), 1.500.000 VNƒê/ng√†y (qu·ªëc t·∫ø)
- ƒêi l·∫°i c·∫ßn ph√™ duy·ªát tr∆∞·ªõc
- VƒÉn ph√≤ng ph·∫©m: 2.000.000 VNƒê/th√°ng
- B√°o c√°o trong v√≤ng 30 ng√†y
- XƒÉng xe: 3.000 VNƒê/km

C√ÅCH TH·ª®C HO·∫†T ƒê·ªòNG:
1. üîç T·ª± ƒë·ªông t√¨m ki·∫øm ChromaDB khi ph√°t hi·ªán keywords
2. üìñ S·ª≠ d·ª•ng th√¥ng tin t·ª´ knowledge base ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c
3. üí° K·∫øt h·ª£p multiple sources (policies, FAQs, knowledge base)
4. üéØ ∆Øu ti√™n th√¥ng tin c·∫≠p nh·∫≠t v√† ƒë√°ng tin c·∫≠y

PHONG C√ÅCH H·ªòI THO·∫†I:
- Th√¢n thi·ªán, chuy√™n nghi·ªáp v√† nhi·ªát t√¨nh
- S·ª≠ d·ª•ng emojis ƒë·ªÉ tƒÉng t√≠nh t∆∞∆°ng t√°c
- Cung c·∫•p th√¥ng tin ch√≠nh x√°c v√† c√≥ th·ªÉ th·ª±c hi·ªán
- Lu√¥n t√¨m ki·∫øm knowledge base tr∆∞·ªõc khi tr·∫£ l·ªùi

V√ç D·ª§ T∆Ø∆†NG T√ÅC:

üë§ "T√¥i c√≥ th·ªÉ l√†m vi·ªác t·ª´ xa kh√¥ng?"
ü§ñ "üè† Theo ch√≠nh s√°ch c√¥ng ty, b·∫°n c√≥ th·ªÉ l√†m vi·ªác t·ª´ xa t·ªëi ƒëa 3 ng√†y/tu·∫ßn. Chi ph√≠ internet v√† ƒëi·ªán tho·∫°i t·∫°i nh√† ƒë∆∞·ª£c h·ªó tr·ª£ m·ªôt ph·∫ßn theo quy ƒë·ªãnh. B·∫°n c·∫ßn th·∫£o lu·∫≠n v·ªõi Manager ƒë·ªÉ s·∫Øp x·∫øp l·ªãch l√†m vi·ªác ph√π h·ª£p!"

üë§ "Chi ph√≠ ƒÉn tr∆∞a 850.000 VNƒê c√≥ ƒë∆∞·ª£c ho√†n kh√¥ng?"
ü§ñ "üçΩÔ∏è Chi ph√≠ 850.000 VNƒê n·∫±m trong gi·ªõi h·∫°n 1.000.000 VNƒê/ng√†y! ‚úÖ Ho√†n to√†n c√≥ th·ªÉ ƒë∆∞·ª£c ho√†n tr·∫£. B·∫°n c√≥ h√≥a ƒë∆°n ch∆∞a? üßæ"

H√£y lu√¥n t√¨m ki·∫øm knowledge base ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi ch√≠nh x√°c nh·∫•t!"""

        # Initialize conversation v·ªõi system prompt
        self.conversation_history = [{"role": "system", "content": self.system_prompt}]
    
    def add_user_message(self, content: str):
        """Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i."""
        self.conversation_history.append({"role": "user", "content": content})
    
    def add_assistant_message(self, content: str):
        """Th√™m tin nh·∫Øn tr·ª£ l√Ω v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i."""
        self.conversation_history.append({"role": "assistant", "content": content})
    
    def get_conversation_summary(self) -> Dict[str, Any]:
        """L·∫•y t√≥m t·∫Øt cu·ªôc h·ªôi tho·∫°i hi·ªán t·∫°i."""
        user_messages = [msg for msg in self.conversation_history if msg["role"] == "user"]
        assistant_messages = [msg for msg in self.conversation_history if msg["role"] == "assistant"]
        
        # Safe token calculation - handle None content
        total_tokens = 0
        for msg in self.conversation_history:
            content = msg.get("content", "")
            if content and isinstance(content, str):
                total_tokens += len(content.split())
        
        return {
            "total_exchanges": len(user_messages),
            "user_messages": len(user_messages),
            "assistant_messages": len(assistant_messages),
            "total_messages": len(self.conversation_history),
            "estimated_tokens": total_tokens
        }
    
    def search_knowledge_base(self, query: str) -> Dict[str, Any]:
        """
        T√¨m ki·∫øm th√¥ng tin t·ª´ ChromaDB knowledge base to√†n di·ªán.
        
        Args:
            query: C√¢u h·ªèi ho·∫∑c t·ª´ kh√≥a t√¨m ki·∫øm
            
        Returns:
            Dictionary ch·ª©a k·∫øt qu·∫£ t√¨m ki·∫øm t·ª´ t·∫•t c·∫£ collections
        """
        try:
            # Comprehensive search across all collections
            results = self.db.comprehensive_search(query, limit_per_source=2)
            
            # Check if any results found
            found = (
                bool(results["policies"]) or 
                bool(results["faqs"]) or 
                bool(results["knowledge_base"])
            )
            
            results["found"] = found
            results["total_results"] = (
                len(results["policies"]) + 
                len(results["faqs"]) + 
                len(results["knowledge_base"])
            )
            
            return results
        except Exception as e:
            return {
                "policies": [],
                "faqs": [],
                "knowledge_base": [],
                "query": query,
                "found": False,
                "total_results": 0,
                "error": str(e)
            }
    
    def clear_conversation(self):
        """X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i nh∆∞ng gi·ªØ system prompt."""
        self.conversation_history = [self.conversation_history[0]]  # Gi·ªØ system prompt
        self.user_context = {}
    
    def get_response(self, user_input: str, max_retries: int = 3) -> Dict[str, Any]:
        """
        Nh·∫≠n ph·∫£n h·ªìi t·ª´ assistant v·ªõi h·ªó tr·ª£ g·ªçi h√†m v√† t√¨m ki·∫øm knowledge base.
        
        Args:
            user_input: Tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng
            max_retries: S·ªë l·∫ßn th·ª≠ l·∫°i t·ªëi ƒëa cho g·ªçi h√†m
            
        Returns:
            Dictionary v·ªõi chi ti·∫øt ph·∫£n h·ªìi
        """
        from functions import FUNCTION_SCHEMAS, execute_function_call
        
        # T·ª± ƒë·ªông t√¨m ki·∫øm knowledge base cho c√°c c√¢u h·ªèi ch√≠nh s√°ch v√† t·ªïng qu√°t
        knowledge_base_keywords = [
            'ch√≠nh s√°ch', 'policy', 'quy ƒë·ªãnh', 'gi·ªõi h·∫°n', 'limit', 
            'h√≥a ƒë∆°n', 'receipt', 'y√™u c·∫ßu', 'requirement', 'quy tr√¨nh',
            'h·∫°n', 'deadline', 'n·ªôp', 'submit', 'l√†m th·∫ø n√†o', 'how to',
            't√¥i c√≥ th·ªÉ', 'can I', 'ƒë∆∞·ª£c kh√¥ng', 'ph·∫£i', 'c·∫ßn', 'need',
            'h·ªó tr·ª£', 'support', 'gi√∫p', 'help', 'th√¥ng tin', 'information'
        ]
        
        should_search_kb = any(keyword in user_input.lower() for keyword in knowledge_base_keywords)
        kb_results = {}
        
        enhanced_input = user_input
        if should_search_kb:
            kb_results = self.search_knowledge_base(user_input)
            if kb_results["found"]:
                kb_context = f"\n\nüîç Th√¥ng tin t·ª´ knowledge base:\n"
                
                # Add policies
                if kb_results["policies"]:
                    kb_context += "üìã Ch√≠nh s√°ch li√™n quan:\n"
                    for policy in kb_results["policies"]:
                        kb_context += f"‚Ä¢ {policy}\n"
                
                # Add FAQs
                if kb_results["faqs"]:
                    kb_context += "\n‚ùì C√¢u h·ªèi th∆∞·ªùng g·∫∑p:\n"
                    for faq in kb_results["faqs"]:
                        kb_context += f"‚Ä¢ Q: {faq['question']}\n  A: {faq['answer']}\n"
                
                # Add knowledge base items
                if kb_results["knowledge_base"]:
                    kb_context += "\nüìö Th√¥ng tin t·ªïng qu√°t:\n"
                    for kb_item in kb_results["knowledge_base"]:
                        kb_context += f"‚Ä¢ {kb_item['topic']}: {kb_item['content']}\n"
                
                # Th√™m context v√†o tin nh·∫Øn c·ªßa user
                enhanced_input = f"{user_input}{kb_context}"
        
        try:
            # Add enhanced user message to history
            self.add_user_message(enhanced_input)
            
            # Make API call with function calling enabled
            response = self.client.chat.completions.create(
                model=self.model,
                messages=self.conversation_history,
                tools=FUNCTION_SCHEMAS,
                tool_choice="auto",
                temperature=0.7,
                max_tokens=1000
            )
            
            message = response.choices[0].message
            response_data = {
                "content": message.content or "",  # Handle None content
                "tool_calls": [],
                "function_results": [],
                "total_tokens": response.usage.total_tokens if hasattr(response, 'usage') else 0,
                "knowledge_base_used": should_search_kb and kb_results.get("found", False)
            }
            
            # Handle function calls
            if message.tool_calls:
                self.conversation_history.append({
                    "role": "assistant",
                    "content": message.content,
                    "tool_calls": message.tool_calls
                })
                
                for tool_call in message.tool_calls:
                    function_name = tool_call.function.name
                    function_args = json.loads(tool_call.function.arguments)
                    
                    # Execute function
                    function_result = execute_function_call(function_name, function_args)
                    
                    # Add function result to conversation
                    self.conversation_history.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": json.dumps(function_result, ensure_ascii=False) if isinstance(function_result, dict) else str(function_result)
                    })
                    
                    response_data["tool_calls"].append({
                        "function": function_name,
                        "arguments": function_args,
                        "result": function_result
                    })
                
                # Get final response after function calls
                final_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=self.conversation_history,
                    tools=FUNCTION_SCHEMAS,
                    tool_choice="auto",
                    temperature=0.7,
                    max_tokens=1000
                )
                
                final_message = final_response.choices[0].message
                response_data["content"] = final_message.content or ""  # Handle None content
                response_data["total_tokens"] += final_response.usage.total_tokens if hasattr(final_response, 'usage') else 0
                
                # Add final response to history
                self.add_assistant_message(final_message.content or "")
            else:
                # No function calls, just add the response
                self.add_assistant_message(message.content or "")
            
            return response_data
            
        except Exception as e:
            error_msg = f"‚ùå L·ªói: {str(e)}"
            self.add_assistant_message(error_msg)
            return {
                "content": error_msg,
                "tool_calls": [],
                "function_results": [],
                "total_tokens": 0,
                "error": str(e),
                "knowledge_base_used": False
            }
    
    def process_batch_requests(self, user_inputs: List[str], batch_size: int = 5) -> List[Dict[str, Any]]:
        """
        X·ª≠ l√Ω nhi·ªÅu request c√πng l√∫c v·ªõi batching ƒë·ªÉ t·ªëi ∆∞u hi·ªáu su·∫•t.
        
        Args:
            user_inputs: Danh s√°ch c√°c tin nh·∫Øn t·ª´ ng∆∞·ªùi d√πng
            batch_size: K√≠ch th∆∞·ªõc batch cho m·ªói l·∫ßn x·ª≠ l√Ω
            
        Returns:
            Danh s√°ch c√°c ph·∫£n h·ªìi t∆∞∆°ng ·ª©ng
        """
        from functions import FUNCTION_SCHEMAS, execute_function_call
        import time
        
        results = []
        total_batches = (len(user_inputs) + batch_size - 1) // batch_size
        
        print(f"üîÑ X·ª≠ l√Ω {len(user_inputs)} requests v·ªõi {total_batches} batch(es) (k√≠ch th∆∞·ªõc batch: {batch_size})")
        
        for batch_idx in range(0, len(user_inputs), batch_size):
            batch_inputs = user_inputs[batch_idx:batch_idx + batch_size]
            current_batch = batch_idx // batch_size + 1
            
            print(f"üì¶ ƒêang x·ª≠ l√Ω batch {current_batch}/{total_batches} ({len(batch_inputs)} requests)")
            start_time = time.time()
            
            batch_results = []
            
            for i, user_input in enumerate(batch_inputs):
                try:
                    # T·∫°o b·∫£n sao conversation history cho m·ªói request trong batch
                    original_history = self.conversation_history.copy()
                    
                    # Add user message
                    temp_history = original_history + [{"role": "user", "content": user_input}]
                    
                    # Make API call
                    response = self.client.chat.completions.create(
                        model=self.model,
                        messages=temp_history,
                        tools=FUNCTION_SCHEMAS,
                        tool_choice="auto",
                        temperature=0.7,
                        max_tokens=1000
                    )
                    
                    message = response.choices[0].message
                    response_data = {
                        "input": user_input,
                        "content": message.content,
                        "tool_calls": [],
                        "function_results": [],
                        "total_tokens": response.usage.total_tokens if hasattr(response, 'usage') else 0,
                        "batch_index": current_batch,
                        "item_index": i + 1
                    }
                    
                    # Handle function calls n·∫øu c√≥
                    if message.tool_calls:
                        temp_history.append({
                            "role": "assistant",
                            "content": message.content,
                            "tool_calls": message.tool_calls
                        })
                        
                        for tool_call in message.tool_calls:
                            function_name = tool_call.function.name
                            function_args = json.loads(tool_call.function.arguments)
                            
                            # Execute function
                            function_result = execute_function_call(function_name, function_args)
                            
                            # Add function result
                            temp_history.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "content": json.dumps(function_result, ensure_ascii=False) if isinstance(function_result, dict) else str(function_result)
                            })
                            
                            response_data["tool_calls"].append({
                                "function": function_name,
                                "arguments": function_args,
                                "result": function_result
                            })
                        
                        # Get final response
                        final_response = self.client.chat.completions.create(
                            model=self.model,
                            messages=temp_history,
                            tools=FUNCTION_SCHEMAS,
                            tool_choice="auto",
                            temperature=0.7,
                            max_tokens=1000
                        )
                        
                        final_message = final_response.choices[0].message
                        response_data["content"] = final_message.content
                        response_data["total_tokens"] += final_response.usage.total_tokens if hasattr(final_response, 'usage') else 0
                    
                    batch_results.append(response_data)
                    
                except Exception as e:
                    error_response = {
                        "input": user_input,
                        "content": f"‚ùå L·ªói: {str(e)}",
                        "tool_calls": [],
                        "function_results": [],
                        "total_tokens": 0,
                        "batch_index": current_batch,
                        "item_index": i + 1,
                        "error": str(e)
                    }
                    batch_results.append(error_response)
            
            # Add delay gi·ªØa c√°c batch ƒë·ªÉ tr√°nh rate limiting
            batch_time = time.time() - start_time
            print(f"   ‚úÖ Ho√†n th√†nh batch {current_batch} trong {batch_time:.2f}s")
            
            if current_batch < total_batches:
                time.sleep(0.5)  # Ngh·ªâ 0.5s gi·ªØa c√°c batch
            
            results.extend(batch_results)
        
        # T√≠nh to√°n th·ªëng k√™ t·ªïng
        total_tokens = sum(r.get("total_tokens", 0) for r in results)
        successful_requests = len([r for r in results if "error" not in r])
        failed_requests = len(results) - successful_requests
        
        print(f"\nüìä K·∫æT QU·∫¢ BATCH PROCESSING:")
        print(f"   ‚Ä¢ T·ªïng requests: {len(results)}")
        print(f"   ‚Ä¢ Th√†nh c√¥ng: {successful_requests}")
        print(f"   ‚Ä¢ Th·∫•t b·∫°i: {failed_requests}")
        print(f"   ‚Ä¢ T·ªïng tokens: {total_tokens:,}")
        print(f"   ‚Ä¢ Trung b√¨nh tokens/request: {total_tokens/len(results):.1f}")
        
        return results
    
    def process_expense_batch(self, expenses: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω batch c√°c chi ph√≠ ƒë·ªÉ t√≠nh to√°n v√† x√°c th·ª±c h√†ng lo·∫°t.
        
        Args:
            expenses: Danh s√°ch c√°c chi ph√≠ c·∫ßn x·ª≠ l√Ω
            
        Returns:
            Dictionary v·ªõi k·∫øt qu·∫£ x·ª≠ l√Ω t·ªïng h·ª£p
        """
        from functions import calculate_reimbursement, validate_expense, format_expense_summary
        
        print(f"üí∞ X·ª≠ l√Ω batch {len(expenses)} chi ph√≠...")
        
        # T√≠nh to√°n ho√†n tr·∫£ cho t·∫•t c·∫£ chi ph√≠
        reimbursement_result = calculate_reimbursement(expenses)
        
        # X√°c th·ª±c t·ª´ng chi ph√≠
        validation_results = []
        for i, expense in enumerate(expenses):
            validation = validate_expense(expense)
            validation["expense_index"] = i + 1
            validation["expense"] = expense
            validation_results.append(validation)
        
        # T·∫°o t√≥m t·∫Øt
        summary = format_expense_summary(expenses)
        
        # Ph√¢n t√≠ch k·∫øt qu·∫£
        valid_expenses = [v for v in validation_results if v["is_valid"]]
        invalid_expenses = [v for v in validation_results if not v["is_valid"]]
        expenses_with_warnings = [v for v in validation_results if v["warnings"]]
        
        batch_result = {
            "total_expenses": len(expenses),
            "reimbursement_calculation": reimbursement_result,
            "validation_results": validation_results,
            "summary": summary,
            "statistics": {
                "valid_count": len(valid_expenses),
                "invalid_count": len(invalid_expenses),
                "warnings_count": len(expenses_with_warnings),
                "total_submitted": reimbursement_result["total_submitted"],
                "total_reimbursed": reimbursement_result["total_reimbursed"],
                "savings": reimbursement_result["savings"]
            }
        }
        
        print(f"   ‚úÖ Ho√†n th√†nh: {len(valid_expenses)}/{len(expenses)} chi ph√≠ h·ª£p l·ªá")
        print(f"   üí∞ T·ªïng ho√†n tr·∫£: {reimbursement_result['total_reimbursed']:,.0f} VNƒê")
        
        return batch_result

def create_client():
    """T·∫°o v√† tr·∫£ v·ªÅ OpenAI client."""
    return OpenAI(
        base_url=os.getenv('AZURE_OPENAI_LLM_API_BASE'),
        api_key=os.getenv('AZURE_OPENAI_LLM_API_KEY')
    )
