# Giao Diá»‡n DÃ²ng Lá»‡nh cho Trá»£ LÃ½ Chi PhÃ­
"""
Giao diá»‡n dÃ²ng lá»‡nh tÆ°Æ¡ng tÃ¡c Ä‘á»ƒ kiá»ƒm tra chatbot vá»›i 
cuá»™c há»™i thoáº¡i nhiá»u lÆ°á»£t, hiá»ƒn thá»‹ pháº£n há»“i vÃ  quáº£n lÃ½ tráº¡ng thÃ¡i cuá»™c trÃ² chuyá»‡n.
"""

import json
from typing import List, Dict, Any
from expense_assistant import ExpenseAssistant, create_client
from functions import MOCK_EXPENSE_REPORTS, EXPENSE_POLICIES, AVAILABLE_FUNCTIONS, SAMPLE_USER_QUERIES

def display_response(response_data: Dict[str, Any]):
    """Hiá»ƒn thá»‹ pháº£n há»“i Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh dáº¡ng tá»« assistant."""
    print("\n" + "="*50)
    print("ğŸ¤– PHáº¢N Há»’I Tá»ª TRá»¢ LÃ:")
    print("="*50)
    
    # Ná»™i dung pháº£n há»“i chÃ­nh
    if response_data.get("content"):
        print(response_data["content"])
    
    # Chi tiáº¿t cÃ¡c láº§n gá»i hÃ m
    if response_data.get("tool_calls"):
        print("\nğŸ”§ CÃC CHá»¨C NÄ‚NG ÄÃƒ Sá»¬ Dá»¤NG:")
        for i, tool_call in enumerate(response_data["tool_calls"], 1):
            print(f"\n   {i}. {tool_call['function']}()")
            print(f"      Tham sá»‘: {json.dumps(tool_call['arguments'], indent=6, ensure_ascii=False)}")
            print(f"      Káº¿t quáº£: {json.dumps(tool_call['result'], indent=6, ensure_ascii=False)}")
    
    # Sá»­ dá»¥ng token
    if response_data.get("total_tokens"):
        print(f"\nğŸ“Š Tokens Ä‘Ã£ sá»­ dá»¥ng: {response_data['total_tokens']}")
    
    print("="*50)

def run_interactive_chat():
    """Cháº¡y phiÃªn chat tÆ°Æ¡ng tÃ¡c vá»›i assistant."""
    print("ğŸš€ Báº¯t Äáº§u Chat TÆ°Æ¡ng TÃ¡c vá»›i Trá»£ LÃ½ Chi PhÃ­")
    print("="*60)
    print("ğŸ’¡ Máº¹o:")
    print("   â€¢ GÃµ 'help' Ä‘á»ƒ xem cÃ¢u há»i máº«u")
    print("   â€¢ GÃµ 'clear' Ä‘á»ƒ Ä‘áº·t láº¡i cuá»™c trÃ² chuyá»‡n")
    print("   â€¢ GÃµ 'summary' Ä‘á»ƒ xem thá»‘ng kÃª cuá»™c trÃ² chuyá»‡n")
    print("   â€¢ GÃµ 'quit' hoáº·c 'exit' Ä‘á»ƒ káº¿t thÃºc phiÃªn")
    print("="*60)
    
    # Khá»Ÿi táº¡o assistant
    client = create_client()
    assistant = ExpenseAssistant(client, model="GPT-4o-mini")
    
    while True:
        try:
            # Nháº­n Ä‘áº§u vÃ o tá»« ngÆ°á»i dÃ¹ng
            user_input = input("\nğŸ‘¤ Báº¡n: ").strip()
            
            # Xá»­ lÃ½ cÃ¡c lá»‡nh Ä‘áº·c biá»‡t
            if user_input.lower() in ['quit', 'exit', 'q', 'thoat']:
                print("\nğŸ‘‹ Cáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng Trá»£ LÃ½ Chi PhÃ­! Táº¡m biá»‡t!")
                break
            
            elif user_input.lower() in ['clear', 'xoa']:
                assistant.clear_conversation()
                print("\nğŸ”„ Cuá»™c trÃ² chuyá»‡n Ä‘Ã£ Ä‘Æ°á»£c xÃ³a. Báº¯t Ä‘áº§u má»›i!")
                continue
            
            elif user_input.lower() in ['summary', 'tong-ket']:
                print(f"\n{assistant.get_conversation_summary()}")
                continue
            
            elif user_input.lower() in ['help', 'giup-do']:
                print("\nğŸ“š CÃ‚U Há»I MáºªU:")
                for i, query in enumerate(SAMPLE_USER_QUERIES[:5], 1):
                    print(f"   {i}. {query}")
                print("\nğŸ’° TÃNH TOÃN CHI PHÃ MáºªU:")
                print("   TÃ­nh hoÃ n tiá»n cho: Äƒn trÆ°a 900.000 VNÄ, taxi 600.000 VNÄ, vÄƒn phÃ²ng pháº©m 1.800.000 VNÄ")
                continue
            
            elif not user_input:
                print("   Vui lÃ²ng nháº­p tin nháº¯n hoáº·c lá»‡nh.")
                continue
            
            # Nháº­n vÃ  hiá»ƒn thá»‹ pháº£n há»“i
            print("\nğŸ¤” Äang xá»­ lÃ½...")
            response = assistant.get_response(user_input)
            display_response(response)
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Chat bá»‹ giÃ¡n Ä‘oáº¡n. Táº¡m biá»‡t!")
            break
        except Exception as e:
            print(f"\nâŒ Lá»—i: {str(e)}")
            print("   Vui lÃ²ng thá»­ láº¡i hoáº·c gÃµ 'quit' Ä‘á»ƒ thoÃ¡t.")

def run_batch_chat(queries: List[str], batch_size: int = 3) -> List[Dict[str, Any]]:
    """
    Cháº¡y batch chat vá»›i nhiá»u queries cÃ¹ng lÃºc.
    
    Args:
        queries: Danh sÃ¡ch cÃ¡c cÃ¢u há»i/queries
        batch_size: KÃ­ch thÆ°á»›c batch
        
    Returns:
        Danh sÃ¡ch káº¿t quáº£
    """
    print(f"ğŸš€ Báº¯t Äáº§u Batch Chat vá»›i {len(queries)} queries")
    print("="*60)
    
    # Khá»Ÿi táº¡o assistant
    client = create_client()
    assistant = ExpenseAssistant(client, model="GPT-4o-mini")
    
    # Process batch
    results = assistant.process_batch_requests(queries, batch_size)
    
    # Hiá»ƒn thá»‹ káº¿t quáº£
    print(f"\nğŸ“‹ CHI TIáº¾T Káº¾T QUáº¢ BATCH:")
    print("="*60)
    
    for i, result in enumerate(results, 1):
        print(f"\n--- Káº¿t quáº£ {i}/{len(results)} ---")
        print(f"ğŸ”¹ Input: {result['input']}")
        print(f"ğŸ”¹ Batch: {result.get('batch_index', 'N/A')}")
        print(f"ğŸ”¹ Tokens: {result.get('total_tokens', 0)}")
        
        if "error" in result:
            print(f"âŒ Lá»—i: {result['error']}")
        else:
            content = result['content']
            if len(content) > 150:
                print(f"ğŸ’¬ Pháº£n há»“i: {content[:150]}...")
            else:
                print(f"ğŸ’¬ Pháº£n há»“i: {content}")
            
            if result.get('tool_calls'):
                print(f"ğŸ”§ Functions gá»i: {len(result['tool_calls'])}")
                for tool_call in result['tool_calls']:
                    print(f"   â€¢ {tool_call['function']}()")
    
    return results

def run_expense_batch_processing(expenses: List[Dict] = None) -> Dict[str, Any]:
    """
    Xá»­ lÃ½ batch cÃ¡c chi phÃ­ Ä‘á»ƒ tÃ­nh toÃ¡n vÃ  xÃ¡c thá»±c hÃ ng loáº¡t.
    
    Args:
        expenses: Danh sÃ¡ch chi phÃ­ (máº·c Ä‘á»‹nh sá»­ dá»¥ng MOCK_EXPENSE_REPORTS)
        
    Returns:
        Káº¿t quáº£ xá»­ lÃ½ batch
    """
    if expenses is None:
        expenses = MOCK_EXPENSE_REPORTS
    
    print(f"ğŸ’° Báº¯t Äáº§u Xá»­ LÃ½ Batch Chi PhÃ­")
    print("="*60)
    print(f"ğŸ“Š Äang xá»­ lÃ½ {len(expenses)} chi phÃ­...")
    
    # Khá»Ÿi táº¡o assistant
    client = create_client()
    assistant = ExpenseAssistant(client, model="GPT-4o-mini")
    
    # Process expense batch
    result = assistant.process_expense_batch(expenses)
    
    # Hiá»ƒn thá»‹ káº¿t quáº£ chi tiáº¿t
    print(f"\nğŸ“‹ Káº¾T QUáº¢ Xá»¬ LÃ BATCH:")
    print("="*60)
    
    stats = result["statistics"]
    print(f"ğŸ“Š THá»NG KÃŠ Tá»”NG QUAN:")
    print(f"   â€¢ Tá»•ng chi phÃ­: {stats['total_submitted']:,.0f} VNÄ")
    print(f"   â€¢ Tá»•ng hoÃ n tráº£: {stats['total_reimbursed']:,.0f} VNÄ")
    print(f"   â€¢ Tiáº¿t kiá»‡m: {stats['savings']:,.0f} VNÄ")
    print(f"   â€¢ Chi phÃ­ há»£p lá»‡: {stats['valid_count']}/{result['total_expenses']}")
    print(f"   â€¢ Chi phÃ­ cÃ³ cáº£nh bÃ¡o: {stats['warnings_count']}")
    print(f"   â€¢ Chi phÃ­ khÃ´ng há»£p lá»‡: {stats['invalid_count']}")
    
    print(f"\nğŸ’° CHI TIáº¾T HOÃ€N TRáº¢:")
    for item in result["reimbursement_calculation"]["breakdown"]:
        print(f"   â€¢ {item['category']}: {item['amount_submitted']:,.0f} VNÄ â†’ {item['amount_reimbursed']:,.0f} VNÄ")
        print(f"     {item['note']}")
    
    print(f"\nâš ï¸  Cáº¢NH BÃO VÃ€ Lá»–I:")
    for validation in result["validation_results"]:
        if validation["warnings"] or validation["errors"]:
            expense = validation["expense"]
            print(f"   â€¢ Chi phÃ­ #{validation['expense_index']}: {expense.get('description', 'N/A')}")
            for warning in validation["warnings"]:
                print(f"     âš ï¸  {warning}")
            for error in validation["errors"]:
                print(f"     âŒ {error}")
    
    return result

def quick_batch_demo():
    """Demo nhanh tÃ­nh nÄƒng batching."""
    print("ğŸ¯ DEMO NHANH TÃNH NÄ‚NG BATCHING")
    print("="*50)
    
    # Demo 1: Batch chat queries
    print("\n1ï¸âƒ£ DEMO BATCH CHAT:")
    sample_queries = [
        "Giá»›i háº¡n chi phÃ­ Äƒn uá»‘ng lÃ  bao nhiá»u?",
        "TÃ´i cÃ³ cáº§n hÃ³a Ä‘Æ¡n cho taxi 300.000 VNÄ khÃ´ng?",
        "TÃ­nh hoÃ n tráº£ cho Äƒn uá»‘ng 1.200.000 VNÄ",
        "ChÃ­nh sÃ¡ch vá» chi phÃ­ Ä‘i láº¡i lÃ  gÃ¬?"
    ]
    
    batch_results = run_batch_chat(sample_queries, batch_size=2)
    
    print(f"\nğŸ“Š Káº¿t quáº£ batch chat: {len(batch_results)} pháº£n há»“i")
    
    # Demo 2: Batch expense processing
    print(f"\n2ï¸âƒ£ DEMO BATCH EXPENSE PROCESSING:")
    expense_results = run_expense_batch_processing()
    
    print(f"\nâœ… Demo hoÃ n thÃ nh! ÄÃ£ xá»­ lÃ½ {len(batch_results)} queries vÃ  {expense_results['total_expenses']} chi phÃ­.")

def run_batch_test(queries: List[str]) -> List[Dict]:
    """
    Cháº¡y kiá»ƒm tra hÃ ng loáº¡t vá»›i nhiá»u truy váº¥n.
    
    Args:
        queries: Danh sÃ¡ch cÃ¡c truy váº¥n kiá»ƒm tra
        
    Returns:
        Danh sÃ¡ch dá»¯ liá»‡u pháº£n há»“i cho má»—i truy váº¥n
    """
    client = create_client()
    assistant = ExpenseAssistant(client, model="GPT-4o-mini")
    
    print(f"ğŸ§ª Cháº¡y kiá»ƒm tra hÃ ng loáº¡t vá»›i {len(queries)} truy váº¥n...")
    results = []
    
    for i, query in enumerate(queries, 1):
        print(f"\n--- Kiá»ƒm tra {i}/{len(queries)} ---")
        print(f"Truy váº¥n: {query}")
        
        response = assistant.get_response(query)
        results.append({
            "query": query,
            "response": response,
            "has_function_calls": len(response.get("tool_calls", [])) > 0,
            "token_count": response.get("total_tokens", 0)
        })
        
        print(f"Pháº£n há»“i: {response['content'][:100]}..." if len(response['content']) > 100 else response['content'])
        print(f"Gá»i hÃ m: {len(response.get('tool_calls', []))}")
    
    return results

def quick_test():
    """Cháº¡y kiá»ƒm tra nhanh cá»§a assistant."""
    print("ğŸš€ Kiá»ƒm Tra Nhanh Trá»£ LÃ½ Chi PhÃ­")
    print("="*40)
    
    client = create_client()
    assistant = ExpenseAssistant(client, model="GPT-4o-mini")
    
    test_queries = [
        "Giá»›i háº¡n chi phÃ­ Äƒn uá»‘ng lÃ  bao nhiá»u?",
        "TÃ­nh hoÃ n tiá»n cho: Äƒn uá»‘ng 900.000 VNÄ, taxi 600.000 VNÄ, cÃ´ng tÃ¡c 24.000.000 VNÄ",
        "TÃ´i cÃ³ cáº§n hÃ³a Ä‘Æ¡n cho táº¥t cáº£ chi phÃ­ khÃ´ng?",
        "TÃ´i cÃ³ chi phÃ­ vÄƒn phÃ²ng pháº©m 3.000.000 VNÄ, Ä‘Æ°á»£c phÃ©p khÃ´ng?"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\nğŸ§ª Kiá»ƒm tra {i}: {query}")
        response = assistant.get_response(query)
        print(f"âœ… Pháº£n há»“i: {response['content']}")
        if response.get('tool_calls'):
            print(f"ğŸ”§ ÄÃ£ sá»­ dá»¥ng {len(response['tool_calls'])} láº§n gá»i hÃ m")

def quick_demo():
    """Cháº¡y demo nhanh hiá»ƒn thá»‹ chá»©c nÄƒng cá»‘t lÃµi."""
    print("âš¡ DEMO NHANH - Chá»©c NÄƒng Cá»‘t LÃµi")
    print("="*40)
    
    client = create_client()
    assistant = ExpenseAssistant(client, model="GPT-4o-mini")
    
    test_query = "TÃ­nh hoÃ n tiá»n cho: Äƒn trÆ°a 900.000 VNÄ, taxi 600.000 VNÄ, vÄƒn phÃ²ng pháº©m 2.400.000 VNÄ"
    print(f"Truy váº¥n kiá»ƒm tra: {test_query}")
    
    response = assistant.get_response(test_query)
    print(f"\nPháº£n há»“i: {response['content']}")
    
    if response.get('tool_calls'):
        print(f"Gá»i hÃ m: {len(response['tool_calls'])}")
        for tc in response['tool_calls']:
            print(f"  â€¢ {tc['function']}() â†’ {tc['result']}")

if __name__ == "__main__":
    print("ğŸ¬ Giao Diá»‡n DÃ²ng Lá»‡nh Trá»£ LÃ½ Chi PhÃ­")
    print("="*30)
    print("CÃ¡c lá»‡nh cÃ³ sáºµn:")
    print("1. run_interactive_chat() - Báº¯t Ä‘áº§u phiÃªn tÆ°Æ¡ng tÃ¡c")
    print("2. quick_test() - Cháº¡y kiá»ƒm tra chá»©c nÄƒng nhanh")
    print("3. quick_demo() - Demo nhanh")
    print("4. run_batch_test(queries) - Cháº¡y kiá»ƒm tra hÃ ng loáº¡t")
    print("5. run_batch_chat(queries, batch_size) - ğŸ†• Batch chat má»›i")
    print("6. run_expense_batch_processing(expenses) - ğŸ†• Batch xá»­ lÃ½ chi phÃ­")
    print("7. quick_batch_demo() - ğŸ†• Demo tÃ­nh nÄƒng Batching")
    
    print("\nğŸš€ TÃNH NÄ‚NG BATCHING Má»šI:")
    print("   â€¢ Xá»­ lÃ½ nhiá»u request cÃ¹ng lÃºc")
    print("   â€¢ Tá»‘i Æ°u hiá»‡u suáº¥t vÃ  token usage")
    print("   â€¢ Batch processing cho chi phÃ­")
    print("   â€¢ Thá»‘ng kÃª vÃ  bÃ¡o cÃ¡o chi tiáº¿t")
    
    print("\nğŸ’¡ Thá»­ ngay:")
    print("   quick_batch_demo()     # Demo Ä‘áº§y Ä‘á»§ tÃ­nh nÄƒng batching")
    print("   run_batch_chat([...])  # Chat vá»›i nhiá»u queries")
    print("   run_expense_batch_processing()  # Xá»­ lÃ½ batch chi phÃ­")
    
    print("\nChá»n má»™t tÃ¹y chá»n:")
    print("1 - Chat tÆ°Æ¡ng tÃ¡c")
    print("2 - Kiá»ƒm tra nhanh")
    print("3 - Demo nhanh")
    print("4 - Demo Batching ğŸ†•")
    print("5 - ThoÃ¡t")
    
    choice = input("\nNháº­p lá»±a chá»n (1-5): ").strip()
    
    if choice == "1":
        run_interactive_chat()
    elif choice == "2":
        quick_test()
    elif choice == "3":
        quick_demo()
    elif choice == "4":
        quick_batch_demo()
    elif choice == "5":
        print("ğŸ‘‹ Táº¡m biá»‡t!")
    else:
        print("Lá»±a chá»n khÃ´ng há»£p lá»‡. Cháº¡y chat tÆ°Æ¡ng tÃ¡c máº·c Ä‘á»‹nh...")
        run_interactive_chat()
