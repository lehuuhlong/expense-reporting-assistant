"""
üîó INTEGRATION MODULE: Smart Conversation Memory
===============================================

Module t√≠ch h·ª£p conversation summarizer v√†o existing system
v·ªõi c√°c optimizations cho expense reporting domain.

Features:
- Drop-in replacement cho existing conversation history
- Automatic summarization v·ªõi domain-specific knowledge
- Token cost optimization
- Seamless integration v·ªõi web app v√† expense assistant
"""

from typing import Dict, List, Any, Optional
from datetime import datetime
import json
from openai import OpenAI

from conversation_summarizer import IntelligentConversationSummarizer, create_summarizer


class SmartConversationMemory:
    """
    üß† Smart wrapper cho conversation management v·ªõi auto-summarization
    
    Thay th·∫ø existing conversation_history arrays v·ªõi intelligent memory
    c√≥ t√≠nh nƒÉng t·ª± ƒë·ªông t√≥m t·∫Øt v√† t·ªëi ∆∞u tokens.
    """
    
    def __init__(self, openai_client: OpenAI, session_id: str = None):
        """
        Kh·ªüi t·∫°o smart conversation memory
        
        Args:
            openai_client: OpenAI client instance
            session_id: Unique session identifier
        """
        self.session_id = session_id or f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.summarizer = create_summarizer(openai_client)
        
        # Compatibility v·ªõi existing ExpenseAssistant interface
        self._system_prompt = None
        self._conversation_history = []  # For compatibility
        
        # Metrics tracking
        self.total_tokens_saved = 0
        self.total_messages = 0
        self.summaries_created = 0
    
    def append(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """
        Th√™m message v√†o conversation v·ªõi auto-summarization
        
        Compatible v·ªõi existing conversation_history.append() calls
        """
        self.total_messages += 1
        
        # Add to summarizer
        result = self.summarizer.add_message(self.session_id, message)
        
        # Update metrics
        if result.get('summarized'):
            self.total_tokens_saved += result.get('tokens_saved', 0)
            self.summaries_created += 1
        
        # Maintain compatibility list
        self._conversation_history.append(message)
        if len(self._conversation_history) > 10:  # Keep only recent for compatibility
            self._conversation_history = self._conversation_history[-10:]
        
        return result
    
    def get_optimized_history(self, include_summaries: bool = True) -> List[Dict[str, Any]]:
        """
        L·∫•y conversation history ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a ƒë·ªÉ g·ª≠i l√™n AI
        
        Returns:
            List of messages bao g·ªìm summaries v√† recent messages
        """
        messages = []
        
        # Add system prompt n·∫øu c√≥
        if self._system_prompt:
            messages.append({"role": "system", "content": self._system_prompt})
        
        if include_summaries:
            # Get conversation context (summaries + recent messages)
            context = self.summarizer.get_conversation_context(self.session_id, max_summaries=2)
            
            if context.strip():
                # Add context nh∆∞ m·ªôt system message
                context_message = {
                    "role": "system", 
                    "content": f"üìö CONTEXT T·ª™ H·ªòI THO·∫†I TR∆Ø·ªöC:\n{context}\n\n---CU·ªòC TR√í CHUY·ªÜN HI·ªÜN T·∫†I---"
                }
                messages.append(context_message)
        
        # Add recent active messages
        if self.session_id in self.summarizer.active_conversations:
            active_messages = self.summarizer.active_conversations[self.session_id]['messages']
            messages.extend(active_messages[-5:])  # Ch·ªâ l·∫•y 5 messages g·∫ßn nh·∫•t
        
        return messages
    
    def get_full_history(self) -> List[Dict[str, Any]]:
        """
        L·∫•y full conversation history (compatibility method)
        Tr·∫£ v·ªÅ recent messages trong memory
        """
        return self._conversation_history.copy()
    
    def clear(self):
        """Clear conversation history"""
        self._conversation_history = []
        if self._system_prompt:
            self._conversation_history.append({"role": "system", "content": self._system_prompt})
    
    def set_system_prompt(self, prompt: str):
        """Set system prompt"""
        self._system_prompt = prompt
        
        # Clear and re-add system prompt
        self._conversation_history = [{"role": "system", "content": prompt}]
    
    def get_stats(self) -> Dict[str, Any]:
        """L·∫•y th·ªëng k√™ performance"""
        summarizer_stats = self.summarizer.get_session_stats(self.session_id)
        
        return {
            **summarizer_stats,
            'total_messages_processed': self.total_messages,
            'total_tokens_saved': self.total_tokens_saved,
            'summaries_created': self.summaries_created,
            'efficiency_ratio': f"{(self.total_tokens_saved / max(1, self.total_messages * 50)) * 100:.1f}%"
        }
    
    # Compatibility properties ƒë·ªÉ work v·ªõi existing code
    @property
    def conversation_history(self):
        """Compatibility property"""
        return self._conversation_history
    
    @conversation_history.setter
    def conversation_history(self, value):
        """Compatibility setter"""
        self._conversation_history = value
    
    def __len__(self):
        """Support len() calls"""
        return len(self._conversation_history)
    
    def __getitem__(self, index):
        """Support indexing"""
        return self._conversation_history[index]
    
    def __iter__(self):
        """Support iteration"""
        return iter(self._conversation_history)


class ExpenseAssistantMemoryUpgrade:
    """
    üöÄ Upgrade existing ExpenseAssistant v·ªõi smart conversation memory
    
    Drop-in replacement cho conversation management
    """
    
    @staticmethod
    def upgrade_assistant(assistant_instance, openai_client: OpenAI) -> 'ExpenseAssistant':
        """
        Upgrade existing ExpenseAssistant instance v·ªõi smart memory
        
        Args:
            assistant_instance: Existing ExpenseAssistant instance
            openai_client: OpenAI client
            
        Returns:
            Enhanced assistant v·ªõi smart conversation memory
        """
        # T·∫°o smart memory
        smart_memory = SmartConversationMemory(
            openai_client=openai_client,
            session_id=f"assistant_{id(assistant_instance)}"
        )
        
        # Migrate existing conversation history
        if hasattr(assistant_instance, 'conversation_history') and assistant_instance.conversation_history:
            for msg in assistant_instance.conversation_history:
                smart_memory.append(msg)
        
        # Replace conversation_history v·ªõi smart memory
        assistant_instance._original_conversation_history = assistant_instance.conversation_history
        assistant_instance.conversation_history = smart_memory._conversation_history
        assistant_instance._smart_memory = smart_memory
        
        # Patch methods ƒë·ªÉ s·ª≠ d·ª•ng smart memory
        original_add_user_message = getattr(assistant_instance, 'add_user_message', None)
        original_add_assistant_message = getattr(assistant_instance, 'add_assistant_message', None)
        
        def enhanced_add_user_message(content):
            message = {"role": "user", "content": content}
            result = smart_memory.append(message)
            
            # Call original method n·∫øu c√≥
            if original_add_user_message:
                return original_add_user_message(content)
        
        def enhanced_add_assistant_message(content):
            message = {"role": "assistant", "content": content}
            result = smart_memory.append(message)
            
            # Call original method n·∫øu c√≥
            if original_add_assistant_message:
                return original_add_assistant_message(content)
        
        # Patch get_response ƒë·ªÉ s·ª≠ d·ª•ng optimized history
        original_get_response = getattr(assistant_instance, 'get_response', None)
        
        def enhanced_get_response(user_input, **kwargs):
            # Add user message
            enhanced_add_user_message(user_input)
            
            # Get optimized history cho AI call
            optimized_history = smart_memory.get_optimized_history()
            
            # Temporarily replace conversation_history
            original_history = assistant_instance.conversation_history
            assistant_instance.conversation_history = optimized_history
            
            try:
                # Call original method
                if original_get_response:
                    result = original_get_response(user_input, **kwargs)
                    
                    # Extract assistant response t·ª´ result
                    if isinstance(result, dict) and 'content' in result:
                        enhanced_add_assistant_message(result['content'])
                    
                    # Add performance metrics
                    if isinstance(result, dict):
                        stats = smart_memory.get_stats()
                        result['memory_stats'] = {
                            'tokens_saved': stats.get('total_tokens_saved', 0),
                            'summaries_created': stats.get('summaries_created', 0),
                            'efficiency': stats.get('efficiency_ratio', '0%')
                        }
                    
                    return result
                else:
                    return {"error": "No get_response method found"}
                    
            finally:
                # Restore original history
                assistant_instance.conversation_history = original_history
        
        # Apply patches
        assistant_instance.add_user_message = enhanced_add_user_message
        assistant_instance.add_assistant_message = enhanced_add_assistant_message
        assistant_instance.get_response = enhanced_get_response
        
        # Add utility methods
        assistant_instance.get_memory_stats = smart_memory.get_stats
        assistant_instance.get_optimized_conversation = smart_memory.get_optimized_history
        
        return assistant_instance


class WebAppMemoryIntegration:
    """
    üåê Integration cho Flask web application
    
    Upgrade web app sessions v·ªõi smart conversation memory
    """
    
    @staticmethod
    def upgrade_session(session_data: Dict[str, Any], openai_client: OpenAI) -> Dict[str, Any]:
        """
        Upgrade web app session v·ªõi smart memory
        
        Args:
            session_data: Existing session data dict
            openai_client: OpenAI client
            
        Returns:
            Enhanced session data v·ªõi smart memory
        """
        session_id = session_data.get('session_id', f"web_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        
        # T·∫°o smart memory cho session
        smart_memory = SmartConversationMemory(
            openai_client=openai_client,
            session_id=session_id
        )
        
        # Add to session data
        session_data['smart_memory'] = smart_memory
        session_data['memory_type'] = 'smart_conversation'
        session_data['memory_stats'] = smart_memory.get_stats()
        
        return session_data
    
    @staticmethod
    def process_message_with_smart_memory(session_data: Dict[str, Any], 
                                        user_message: str, 
                                        assistant_response: str) -> Dict[str, Any]:
        """
        Process message exchange v·ªõi smart memory
        
        Returns:
            Updated session data v·ªõi memory metrics
        """
        if 'smart_memory' not in session_data:
            return session_data
        
        smart_memory = session_data['smart_memory']
        
        # Add user message
        user_result = smart_memory.append({"role": "user", "content": user_message})
        
        # Add assistant response
        assistant_result = smart_memory.append({"role": "assistant", "content": assistant_response})
        
        # Update session stats
        session_data['memory_stats'] = smart_memory.get_stats()
        
        # Add performance info
        session_data['last_memory_result'] = {
            'user_message_result': user_result,
            'assistant_message_result': assistant_result
        }
        
        return session_data
    
    @staticmethod
    def get_context_for_ai(session_data: Dict[str, Any]) -> str:
        """
        L·∫•y context ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a ƒë·ªÉ g·ª≠i c√πng request l√™n AI
        """
        if 'smart_memory' not in session_data:
            return ""
        
        smart_memory = session_data['smart_memory']
        return smart_memory.summarizer.get_conversation_context(smart_memory.session_id)


# Factory functions ƒë·ªÉ d·ªÖ d√†ng integrate
def create_smart_memory_for_session(openai_client: OpenAI, session_id: str = None) -> SmartConversationMemory:
    """Factory function t·∫°o smart memory cho session"""
    return SmartConversationMemory(openai_client, session_id)


def upgrade_existing_assistant(assistant_instance, openai_client: OpenAI):
    """Upgrade existing assistant v·ªõi smart memory"""
    return ExpenseAssistantMemoryUpgrade.upgrade_assistant(assistant_instance, openai_client)


if __name__ == "__main__":
    # Demo integration
    print("üß† Smart Conversation Memory Integration Demo")
    print("=" * 50)
    
    # Mock OpenAI client for demo
    class MockOpenAI:
        pass
    
    client = MockOpenAI()
    
    # Demo 1: Smart Memory
    print("1. Creating Smart Memory...")
    smart_memory = create_smart_memory_for_session(client, "demo_session")
    
    # Demo conversation
    messages = [
        {"role": "user", "content": "K√™ khai chi ph√≠ ƒÉn tr∆∞a 150k"},
        {"role": "assistant", "content": "ƒê√£ ghi nh·∫≠n chi ph√≠ ƒÉn tr∆∞a"},
        {"role": "user", "content": "Chi ph√≠ taxi 50k"},
        {"role": "assistant", "content": "ƒê√£ ghi nh·∫≠n chi ph√≠ taxi"}
    ]
    
    for msg in messages:
        result = smart_memory.append(msg)
        print(f"   Added message: {msg['content'][:30]}... | Summarized: {result.get('summarized', False)}")
    
    print(f"   Memory stats: {smart_memory.get_stats()}")
    
    # Demo 2: Web App Integration  
    print("\n2. Web App Integration Demo...")
    session_data = {'session_id': 'web_demo'}
    upgraded_session = WebAppMemoryIntegration.upgrade_session(session_data, client)
    print(f"   Session upgraded: {upgraded_session.get('memory_type')}")
    
    print("\n‚úÖ Integration demos completed successfully!")
